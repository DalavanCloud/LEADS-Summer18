{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Change these paths\n",
    "java_path = \"/Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/java.exec\"\n",
    "jar = '/Users/gretchenstahlman/stanford-ner-2018-02-27/stanford-ner.jar'\n",
    "model = '/Users/gretchenstahlman/stanford-ner-2018-02-27/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "directory = \"/Users/gretchenstahlman/Documents/Geoparsing/Expanding Access\"\n",
    "\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
    "\n",
    "out_dict = {}\n",
    "\n",
    "t = 0\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read() \n",
    "            text = ner_tagger.tag(word_tokenize(text))\n",
    "            locations = []\n",
    "            current_loc = []\n",
    "            is_prev_loc = 0\n",
    "            for word in text:\n",
    "                if word[1] == \"LOCATION\":\n",
    "                    if is_prev_loc == 1:\n",
    "                        current_loc.append(word[0])\n",
    "                    else:\n",
    "                        locations.append(current_loc)\n",
    "                        current_loc = [word[0]]\n",
    "                        is_prev_loc = 1\n",
    "                else:\n",
    "                    is_prev_loc = 0\n",
    "            loc_list = []\n",
    "            for i in locations[1:]:\n",
    "                if len(i) > 1:\n",
    "                    exp = \" \".join(locations[1])\n",
    "                    loc_list.append(exp)\n",
    "                else:\n",
    "                    loc_list.append(i)\n",
    "        out_dict[filename] = loc_list\n",
    "        f.close()\n",
    "        t += 1\n",
    "        print(str(t) + \" files have been processed.\")\n",
    "\n",
    "with open(directory + '/geo.json', 'w') as outfile:\n",
    "    json.dump(out_dict, outfile)\n",
    "\n",
    "# Chunk to detect unreadable files\n",
    "import os\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            try: text = f.read() \n",
    "            except: \n",
    "                print(filename + \"error\")\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
